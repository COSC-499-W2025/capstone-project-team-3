#Non code Analysis 

##Non 3rd party Analsysi of non code files.

Here’s a detailed, step-by-step explanation of **how code analyzes non-code files without using AI models** (i.e., using offline NLP, pattern matching, and rule-based logic):

---

## **1. File Parsing and Input**

- The analysis starts with a dictionary like `parsed_files = {"files": [...]}`.
- Each entry in `files` contains:
  - `success`: Whether parsing succeeded.
  - `content`: The extracted text.
  - `path`: The file path.

---

## **2. Document Type Classification**

- For each file, `classify_document_type(content, file_path)` is called.
- This function uses:
  - **Filename patterns** (e.g., "README", "LICENSE", "meeting_notes") to quickly classify common documentation types.
  - **Content-based rules**: If filename doesn’t match, it looks for keywords in the content (e.g., "api", "endpoint", "requirements", "design", "architecture", etc.).
- No AI: This is pure string matching and counting.

---

## **3. Skill Extraction**

- For each file, `extract_all_skills(content)` is called.
- This function uses:
  - **Hardcoded keyword sets** for technical skills (e.g., "python", "docker", "aws").
  - **Pattern matching** for soft skills, domain expertise, tools, and writing skills.
  - **Simple regular expressions** to find matches in the content.
- No AI: All skills are extracted by searching for known keywords and phrases.

---

## **4. Project-Level Aggregation**

- All successful file contents are concatenated into `project_content`.
- Skills from all files are merged into project-level skill sets (using Python sets for uniqueness).

---

## **5. Domain Detection**

- The code checks for the presence of domain-specific keywords (e.g., "data", "model", "business", "health") in the aggregated content.
- The domain with the most keyword matches is selected as the primary domain.

---

## **6. Document Type Summary**

- Counts the most common document types across all files.
- Maps these types to human-readable phrases (e.g., "README documentation", "API documentation").

---

## **7. Feature Detection**

- Checks for the presence of important project features using keyword searches:
  - **Architecture**: Looks for "architecture", "design", "microservice".
  - **Requirements**: Looks for "requirement", "specification".
  - **NLP/Parsing**: Looks for "parse", "nlp", "analysis".
  - **Risks/Testing**: Looks for "risk", "testing", "performance".

---

## **8. Summary Generation**

- Builds a summary sentence-by-sentence:
  - What types of documentation exist.
  - What domain the documentation is in.
  - What features are described (architecture, requirements, NLP, risks).
  - If nothing else, a generic summary is added.

---

## **9. Bullet Point Extraction**

- Adds bullet points for each detected feature (architecture, requirements, etc.).
- Adds a bullet for top technologies used.
- Calls `extract_contribution_bullets` to generate additional bullet points from the content:
  - Uses pattern matching, action verbs, and filters out generic or irrelevant sentences.
  - Ensures bullets are concise and relevant.

---

## **10. Final Output**

- Returns a dictionary with:
  - `"summary"`: The high-level summary of the project documentation.
  - `"bullets"`: 4–5 key bullet points about contributions and features.
  - `"skills"`: Aggregated lists of technical, soft, domain, tool, and writing skills.

---

## **Key Points**

- **No AI models are used**: All analysis is done with offline NLP libraries (spaCy, NLTK, TextBlob, Sumy) and hardcoded rules.
- **Pattern matching and keyword search** are the main techniques.
- **No external API calls** or LLMs—everything runs locally and deterministically.
- **Extensible**: You can add more keywords, patterns, or rules to improve detection.

---

## **Summary Table**

| Step                | Technique Used         | AI/ML? | Example Logic                        |
|---------------------|-----------------------|--------|--------------------------------------|
| File Parsing        | Text extraction       | No     | Read file, extract text              |
| Doc Type Detection  | Filename/content      | No     | "README.md" → README                 |
| Skill Extraction    | Keyword search        | No     | "python" in content → Python skill   |
| Domain Detection    | Keyword counting      | No     | Most matches → selected domain       |
| Feature Detection   | Keyword search        | No     | "architecture" → has_architecture    |
| Summary Generation  | Rule-based sentences  | No     | Compose summary from findings        |
| Bullet Extraction   | Pattern matching      | No     | Action verbs, filter sentences       |

---

## All of the above has been done in sync with analysis for non code files using Ai and analysis of code files."
